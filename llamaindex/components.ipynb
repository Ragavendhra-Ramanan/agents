{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "dataset = load_dataset(path=\"dvilasuero/finepersonas-v0.1-tiny\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data\").mkdir(parents=True,exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, persona in enumerate(dataset):\n",
    "    with open(Path(\"data\") / f\"persona_{i}.txt\", \"w\") as f:\n",
    "        f.write(persona[\"persona\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load and embed documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(input_dir=\"data\")\n",
    "documents = reader.load_data()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.embeddings.huggingface_api import HuggingFaceInferenceAPIEmbedding\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[SentenceSplitter(),\n",
    "                     HuggingFaceInferenceAPIEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")]\n",
    ")\n",
    "nodes = await pipeline.arun(documents=documents[:10])\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **vector store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "db = chromadb.PersistentClient(path=\"./alfred_chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(name=\"alfred\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[SentenceSplitter(),\n",
    "                     HuggingFaceInferenceAPIEmbedding(model_name=\"BAAI/bge-small-en-v1.5\"),\n",
    "                   ],  vector_store=vector_store,\n",
    ")\n",
    "nodes = await pipeline.arun(documents=documents[:10])\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Get index to query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface_api import HuggingFaceInferenceAPIEmbedding\n",
    "\n",
    "embed_model = HuggingFaceInferenceAPIEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=\"An individual deeply versed in the nuances of Cypriot culture, history, and society, having dedicated significant time to research and reside in Cyprus. This person has immersed themselves in the local customs and way of life, offering a rich perspective on the island's cultural tapestry.\", source_nodes=[NodeWithScore(node=TextNode(id_='8ce9cc96-80e5-487e-aa98-b64a582e181a', embedding=None, metadata={'file_path': 'c:\\\\Users\\\\raman\\\\Downloads\\\\Agents\\\\Agents_Codes\\\\llamaindex\\\\data\\\\persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-03-08', 'last_modified_date': '2025-03-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='48b24699-9ffb-469b-86fb-d01e1597be4d', node_type='4', metadata={'file_path': 'c:\\\\Users\\\\raman\\\\Downloads\\\\Agents\\\\Agents_Codes\\\\llamaindex\\\\data\\\\persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-03-08', 'last_modified_date': '2025-03-08'}, hash='e6c87149a97bf9e5dbdf33922a4e5023c6b72550ca0b63472bd5d25103b28e99')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An anthropologist or a cultural expert interested in the intricacies of Cypriot culture, history, and society, particularly someone who has spent considerable time researching and living in Cyprus to gain a deep understanding of its people, customs, and way of life.', mimetype='text/plain', start_char_idx=0, end_char_idx=266, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5216276346507599), NodeWithScore(node=TextNode(id_='c9371594-831b-4652-bdcc-3dabd0418498', embedding=None, metadata={'file_path': 'c:\\\\Users\\\\raman\\\\Downloads\\\\Agents\\\\Agents_Codes\\\\llamaindex\\\\data\\\\persona_102.txt', 'file_name': 'persona_102.txt', 'file_type': 'text/plain', 'file_size': 112, 'creation_date': '2025-03-08', 'last_modified_date': '2025-03-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='8de85fc3-bbcb-486d-8721-90066aef940c', node_type='4', metadata={'file_path': 'c:\\\\Users\\\\raman\\\\Downloads\\\\Agents\\\\Agents_Codes\\\\llamaindex\\\\data\\\\persona_102.txt', 'file_name': 'persona_102.txt', 'file_type': 'text/plain', 'file_size': 112, 'creation_date': '2025-03-08', 'last_modified_date': '2025-03-08'}, hash='9a05cec6f6476fcd20b0a64ae8a104d6d794a78fa1335017fd7286ec483dfa34')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='A literacy specialist or reading teacher focused on supporting students with reading comprehension difficulties.', mimetype='text/plain', start_char_idx=0, end_char_idx=112, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5209936886704079)], metadata={'8ce9cc96-80e5-487e-aa98-b64a582e181a': {'file_path': 'c:\\\\Users\\\\raman\\\\Downloads\\\\Agents\\\\Agents_Codes\\\\llamaindex\\\\data\\\\persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-03-08', 'last_modified_date': '2025-03-08'}, 'c9371594-831b-4652-bdcc-3dabd0418498': {'file_path': 'c:\\\\Users\\\\raman\\\\Downloads\\\\Agents\\\\Agents_Codes\\\\llamaindex\\\\data\\\\persona_102.txt', 'file_name': 'persona_102.txt', 'file_type': 'text/plain', 'file_size': 112, 'creation_date': '2025-03-08', 'last_modified_date': '2025-03-08'}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    response_mode = \"tree_summarize\",\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"Respond using a persona that describes author and travel experience\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
    "\n",
    "# query index\n",
    "evaluator = FaithfulnessEvaluator(llm=llm)\n",
    "eval_result = evaluator.evaluate_response(response=response)\n",
    "eval_result.passing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
